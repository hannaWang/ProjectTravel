{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Google Map\n",
    "- 換ip:proxy list,safeip\n",
    "- 換headers\n",
    "- 多線進程:grequest, greenlet(可用手機換ip)\n",
    "- 步驟:1.selenium自動景點搜尋\n",
    "- ........2.法一:原圖 w/ XML,法二:縮圖 w/ HTML上的links \n",
    "- <img src=\"mapImg.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GoogleMap Img w/ 原圖(單點)\n",
    "- 按下\"201張照片\", JS生成一.json檔含100張圖片原始與縮圖連結.\n",
    "- 手動輸入搜尋地點, 開啟Neteork下的XHR:photo?author=0..., 送出RequestURL接收Response:.json\n",
    "- 目前有驗證的問題:也許可使用Ajax解決"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#完整版\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import io\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "\n",
    "loc = \"Awaji Island\"\n",
    "img_ReqUrl={}\n",
    "reqUrl='https://www.google.com.tw/maps/preview/photo?authuser=0&hl=zh-TW&pb=!1e2!3m2!1s0x3554ba6dbfc4cfe1%3A0xaad592bb86ce307e\\\n",
    "!9e0!5m42!2m2!1i203!2i100!3m1!2i100!7m35!1m3!1e1!2b0!3e3!1m3!1e2!2b1!3e2!1m3!1e2!2b0!3e3!1m3!1e3!2b0!3e3!1m3!1e4!2b0!3e3!1m3!1e8!2b0!3e3\\\n",
    "!1m3!1e3!2b1!3e2!1m4!1e5!2b0!3e1!4e2!2b1!4b1!9b0!6m3!1sjhJlV6jMHsGZ0gTz47HQDA!7e81!15i16698'\n",
    "\n",
    "headers = {'user-agent':'Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:46.0) Gecko/20100101 Firefox/46.0'} \n",
    "res = requests.get(reqUrl, headers = headers)\n",
    "\n",
    "#文字轉.json\n",
    "imgjson = res.text.split(')]}\\'')[1]\n",
    "with io.open('E:/ProjectTravel/IMG/temp.json', 'w', encoding='utf-8') as file:\n",
    "    file.write(imgjson)\n",
    "    \n",
    "#.json讀入\n",
    "with open('E:/ProjectTravel/IMG/temp.json', 'r') as f:\n",
    "    hrefs = json.load(f)\n",
    "\n",
    "#改寫連結\n",
    "imghrefs=[]\n",
    "for i in xrange(0,len(hrefs[0])):\n",
    "    #print hrefs[0][i][0]\n",
    "    #print \"-------------------------------------------------------------------------\"\n",
    "    if re.search('^(\\d)+$',hrefs[0][i][0]):\n",
    "        imghrefs.append(\"https://static.panoramio.com.storage.googleapis.com/photos/1920x1280/\"+hrefs[0][i][0]+\".jpg\") \n",
    "        print imghrefs[-1]\n",
    "    elif re.search('^-(.{22,})',hrefs[0][i][0]):\n",
    "        imghrefs.append(\"https://lh3.ggpht.com/\" + hrefs[0][i][0] + \"/s2000/photo\") \n",
    "        print imghrefs[-1]\n",
    "    elif re.search('^http',hrefs[0][i][0]):\n",
    "        imghrefs.append(hrefs[0][i][0])\n",
    "        print imghrefs[-1]\n",
    "    else:\n",
    "        print hrefs[0][i][0]\n",
    "\n",
    "#連結寫出保存     \n",
    "img_ReqUrl[loc]=[reqUrl,imghrefs]\n",
    "with open('E:/ProjectTravel/IMG/img_ReqUrl.json' , 'a') as f:\n",
    "    json.dump(img_ReqUrl, f)\n",
    "          \n",
    "#動態建立資料夾\n",
    "dir = loc\n",
    "os.mkdir('E:/ProjectTravel/IMG/'+dir)\n",
    "\n",
    "#下載\n",
    "import requests\n",
    "import shutil \n",
    "for i in xrange(0,len(imghrefs)):\n",
    "    url = imghrefs[i]\n",
    "    res = requests.get(url, stream=True)\n",
    "    fname = loc+'{:0>4}'.format(i+1)+'.jpg'\n",
    "    with open('E:/ProjectTravel/IMG/Awaji Island/'+fname, 'wb') as f:\n",
    "        shutil.copyfileobj(res.raw, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 連結寫出保存     \n",
    "img_ReqUrl[loc]=[reqUrl,imghrefs]\n",
    "with open('E:/ProjectTravel/IMG/img_ReqUrl.json' , 'a') as f:\n",
    "    json.dump(img_ReqUrl, f)\n",
    "        \n",
    "#動態建立資料夾\n",
    "dir = loc\n",
    "os.mkdir('E:/ProjectTravel/IMG/'+dir)\n",
    "\n",
    "#下載\n",
    "import requests\n",
    "import shutil \n",
    "for i in xrange(0,len(imghrefs)):\n",
    "    url = imghrefs[i]\n",
    "    res = requests.get(url, stream=True)\n",
    "    fname = loc+'{:0>4}'.format(i+1)+'.jpg'\n",
    "    with open('E:/ProjectTravel/IMG/'+dir+'/'+fname, 'wb') as f:\n",
    "        shutil.copyfileobj(res.raw, f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "list=[[[1,2,3]]]\n",
    "print list[0][0][1]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import io\n",
    "import json\n",
    "\n",
    "headers = {'user-agent':'Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:46.0) Gecko/20100101 Firefox/46.0'} \n",
    "res = requests.get('https://www.google.com.tw/maps/preview/photo?authuser=0&hl=zh-TW&pb=!1e2!3m2!1s0x3554ba6dbfc4cfe1%3A0xaad592bb86ce307e\\\n",
    "!9e0!5m42!2m2!1i203!2i100!3m1!2i100!7m35!1m3!1e1!2b0!3e3!1m3!1e2!2b1!3e2!1m3!1e2!2b0!3e3!1m3!1e3!2b0!3e3!1m3!1e4!2b0!3e3!1m3!1e8!2b0!3e3\\\n",
    "!1m3!1e3!2b1!3e2!1m4!1e5!2b0!3e1!4e2!2b1!4b1!9b0!6m3!1sjhJlV6jMHsGZ0gTz47HQDA!7e81!15i16698', headers = headers)\n",
    "\n",
    "json = res.text.split(')]}\\'')[1]\n",
    "#文字檔匯出成.json\n",
    "with io.open('E:/ProjectTravel/test.json', 'w', encoding='utf-8') as file:\n",
    "    file.write(json)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#.json讀入\n",
    "import re\n",
    "\n",
    "with open('E:/ProjectTravel/test.json' , 'r') as f:\n",
    "    hrefs = json.load(f)\n",
    "    \n",
    "#print len(hrefs[0])\n",
    "imghrefs=[]\n",
    "for i in xrange(0,len(hrefs[0])):\n",
    "    #print hrefs[0][i][0]\n",
    "    #print \"-------------------------------------------------------------------------\"\n",
    "    if re.search('^(\\d)+$',hrefs[0][i][0]):\n",
    "        imghrefs.append(\"https://static.panoramio.com.storage.googleapis.com/photos/1920x1280/\" + hrefs[0][i][0] + \".jpg\") \n",
    "        print imghrefs[-1]\n",
    "    elif re.search('^-',hrefs[0][i][0]):\n",
    "        imghrefs.append(\"https://lh3.ggpht.com/\" + hrefs[0][i][0] + \"/s2500/photo\") \n",
    "        print imghrefs[-1]\n",
    "    elif re.search('^http',hrefs[0][i][0]):\n",
    "         print imghrefs[-1]\n",
    "    else:\n",
    "        print hrefs[0][i][0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#動態建立資料夾\n",
    "import os\n",
    "dir = u'Awaji-shima'\n",
    "os.mkdir('E:/ProjectTravel/IMG/'+dir)\n",
    "\n",
    "#下載\n",
    "import requests\n",
    "import shutil \n",
    "for i in xrange(0,len(imghrefs)):\n",
    "    url = imghrefs[i]\n",
    "    res = requests.get(url, stream=True)\n",
    "    fname = 'Awaji-shima'+'{:0>4}'.format(i+1)+'.jpg'\n",
    "    with open('E:/ProjectTravel/IMG/Awaji-shima/'+fname, 'wb') as f:\n",
    "        shutil.copyfileobj(res.raw, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GoogleMap Img w/ 縮圖(多點)\n",
    "- 自動輸入地點,改寫縮圖連結,少於100張圖片\n",
    "- continue,break,pass：https://docs.python.org/2/tutorial/controlflow.html"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#解決class由JS生成的問題：ActionChains\n",
    "#http://selenium-python.readthedocs.io/api.html\n",
    "menu = driver.find_element_by_css_selector(\".nav\")\n",
    "#hidden_submenu = driver.find_element_by_css_selector(\".nav #submenu1\") #因為.nav #submenu1不存在,使用on_element=None\n",
    "ActionChains(driver).move_to_element(menu).click(on_element=None).perform()\n",
    "\n",
    "#wait直到生成\n",
    "#http://www.seleniumhq.org/docs/04_webdriver_advanced.jsp\n",
    "#http://selenium-python.readthedocs.io/waits.html (使用By.CSS_SELECTOR, By.CLASS_NAME不能用 )\n",
    "#https://seleniumhq.github.io/selenium/docs/api/py/webdriver_support/selenium.webdriver.support.expected_conditions.html\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "wait = WebDriverWait(driver, 10)\n",
    "element = wait.until(EC.element_to_be_clickable((By.ID,'someid')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNKNOWN﻿有樂町\n",
      "0 1\n",
      "0 44\n",
      "0 97\n",
      "0 53\n",
      "東武百貨店池袋店\n",
      "Terrace City\n",
      "Coppice\n",
      "台場Mediage\n",
      "0 100\n",
      "0 100\n",
      "TOKYO CRUISE\n",
      "0 15\n",
      "江戶城\n",
      "アカチャンホンポ アルカキット錦糸町店\n",
      "忠犬八公\n",
      "友都八喜\n",
      "0 31\n",
      "0 80\n",
      "慶應義塾大學\n",
      "0 1\n",
      "Tokyo Odaiba Oedo Onsen Monogatari\n"
     ]
    }
   ],
   "source": [
    "#使用googlemap搜尋景點,取得景點相片連結\n",
    "\n",
    "import codecs,os\n",
    "with codecs.open('C:/Users/BIG DATA/Downloads/jptoursmall..txt', 'r', encoding='utf-8') as file:\n",
    "    attr = file.readlines()\n",
    "uniattr=[attr[i].strip() for i in xrange(0,len(attr))]\n",
    "\n",
    "for i in xrange(0,len(uniattr)):\n",
    "    loc=uniattr[i]\n",
    "    if os.path.isdir('E:/ProjectTravel/IMG/'+loc):\n",
    "        #print \"yes\"+loc\n",
    "        continue\n",
    "    else:    \n",
    "        from selenium import webdriver\n",
    "        from selenium.webdriver.common.by import By\n",
    "        from selenium.webdriver.common.keys import Keys\n",
    "        from selenium.webdriver.support.ui import Select\n",
    "        from selenium.webdriver.support.ui import WebDriverWait\n",
    "        from selenium.webdriver.support import expected_conditions as EC\n",
    "        from selenium.common.exceptions import NoSuchElementException\n",
    "        from selenium.common.exceptions import NoAlertPresentException\n",
    "        from selenium.webdriver.common.action_chains import ActionChains\n",
    "        import unittest, time, re\n",
    "        from bs4 import BeautifulSoup \n",
    "        import json\n",
    "        import codecs\n",
    "\n",
    "        driver = webdriver.Firefox()\n",
    "        #放到最大避免找不到element\n",
    "        driver.set_window_size(1024, 600)\n",
    "        driver.maximize_window()\n",
    "        driver.implicitly_wait(30) #最多等30s\n",
    "        base_url = \"https://www.google.com.tw\"\n",
    "        driver.get(base_url + \"/maps\")\n",
    "        #wait直到JS生成搜尋鈕:\n",
    "        wait = WebDriverWait(driver,20).until(EC.visibility_of_element_located((By.CSS_SELECTOR, 'div.scene-footer-container.noprint')))\n",
    "        driver.find_element_by_id(\"searchboxinput\").send_keys(loc)\n",
    "        #移動到搜尋鈕並按下\n",
    "        search = driver.find_element_by_css_selector(\"button.searchbox-searchbutton\") \n",
    "        ActionChains(driver).move_to_element(search).click(on_element=None).perform()\n",
    "\n",
    "        try:\n",
    "            if len(driver.find_elements_by_css_selector(\"label.widget-pane-section-image-pack-label\")) < 2:\n",
    "                print uniattr[i]\n",
    "                driver.quit()\n",
    "                continue\n",
    "        except:\n",
    "            print uniattr[i]\n",
    "            driver.quit()\n",
    "\n",
    "        else:\n",
    "            #取得google景點名\n",
    "            soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "            wait = WebDriverWait(driver,20).until(EC.visibility_of_element_located((By.CSS_SELECTOR, 'div.widget-pane-section-header-title')))\n",
    "            engloc = soup.select(\"div.widget-pane-section-header-title h1\")[0].text\n",
    "            driver.find_elements_by_css_selector(\"button.widget-pane-section-header-hero.widget-pane-fading.widget-pane-fade-in.widget-pane-section-header-hero-clickable\")[-1].click()          \n",
    "            #\"XX 張相片\"\n",
    "            qty=[int(howmany.text.split()[0]) for howmany in soup.select('label.widget-pane-section-image-pack-label > span') if re.search('^\\d{1,3}', howmany.text)]                \n",
    "            #\"相片\"\n",
    "            try:\n",
    "                if qty[0] > 100 :\n",
    "                    qty[0] = 100\n",
    "                elif qty[0] < 10 :\n",
    "                    qty[0] = 1\n",
    "                elif len(qty) == 0:\n",
    "                    print \"unknow howmany\"+uniattr[i]\n",
    "            except:\n",
    "                qty.append(1)\n",
    "                print \"UNKNOWN\"+uniattr[i]\n",
    "            \n",
    "            #等待取得小圖連結\n",
    "            soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "            while len(soup.select('img.widget-runway-card-background-flicker-hack')) <= qty[0]*0.8:\n",
    "                print len(soup.select('img.widget-runway-card-background-flicker-hack')),qty[0]\n",
    "                lastImg=driver.find_element_by_css_selector(\"button.widget-runway-photo-upload-button\")\n",
    "                lastImg.location_once_scrolled_into_view\n",
    "                search = driver.find_elements_by_css_selector(\"button.widget-runway-card-button\")[-1]\n",
    "                ActionChains(driver).move_to_element(search).click(on_element=None).perform()\n",
    "                time.sleep(30)\n",
    "                soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "            #改寫連結\n",
    "            locImgHref=[]\n",
    "            for l in soup.select('img.widget-runway-card-background-flicker-hack'):\n",
    "                if \"proxy\" in l[\"src\"]:\n",
    "                    locImgHref.append(\"https:\" + l[\"src\"].split(\"=w\")[0] + \"=w5000\") \n",
    "                    #print locImgHref\n",
    "                elif \"/w\" in l[\"src\"]:\n",
    "                    locImgHref.append(\"https:\" + l[\"src\"].split(\"/w\")[0] + \"/w5000/photo\") #/w:可能環景圖\n",
    "                    #print l[\"src\"]\n",
    "                elif \"ggpht.com\" in l[\"src\"]:\n",
    "                    continue\n",
    "                else:\n",
    "                    locImgHref.append(\"https:\" + l[\"src\"].split(\"/s\")[0] + \"/s5000/photo\")\n",
    "                    #print l[\"src\"]\n",
    "            driver.quit()\n",
    "\n",
    "            #連結寫出保存\n",
    "            imgsmall_ReqUrl={}\n",
    "            imgsmall_ReqUrl[loc]=[engloc,locImgHref]\n",
    "            with open('E:/ProjectTravel/IMG/imgSmall_ReqUrl.json', 'a') as f:\n",
    "                json.dump(imgsmall_ReqUrl, f)           \n",
    "            #動態建立資料夾\n",
    "            import os\n",
    "            loc=uniattr[i]\n",
    "            os.mkdir('E:/ProjectTravel/IMG/'+loc)\n",
    "            #下載\n",
    "            import requests\n",
    "            import shutil \n",
    "            for i in xrange(0,len(locImgHref)):\n",
    "                url = locImgHref[i]\n",
    "                res = requests.get(url, stream=True)\n",
    "                fname = loc+'{:0>4}'.format(i+1)+'.jpg'\n",
    "                with open('E:/ProjectTravel/IMG/'+loc+'/'+fname, 'wb') as f:\n",
    "                    shutil.copyfileobj(res.raw, f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "qty=[]\n",
    "if len(qty) == 0:\n",
    "    qty.append(10)\n",
    "print qty[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#search = driver.find_elements_by_css_selector(\"button.widget-runway-photo-upload-button\")\n",
    "#ActionChains(driver).move_to_element(search).click(on_element=None).perform()\n",
    "\n",
    "element=driver.find_element_by_css_selector(\"button.widget-runway-photo-upload-button\")\n",
    "element.location_once_scrolled_into_view"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#for howmany in soup.select('label.widget-pane-section-image-pack-label > span'): \n",
    "    #print  repr(howmany.text)\n",
    "#    if re.search('^\\d{2,3}', howmany.text):\n",
    "#        qty = int(howmany.text.split()[0])\n",
    "\n",
    "qty=[int(howmany.text.split()[0]) for howmany in soup.select('label.widget-pane-section-image-pack-label > span') if re.search('^\\d{2,3}', howmany.text)]\n",
    "print qty[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import codecs,os\n",
    "with codecs.open('C:/Users/BIG DATA/Downloads/jptour.txt', 'r', encoding='utf-8') as file:\n",
    "    attr = file.readlines()\n",
    "uniattr=[]\n",
    "for i in xrange(0,len(attr)):\n",
    "    uattr = attr[i].strip()\n",
    "    uniattr.append(uattr)\n",
    "\n",
    "for i in xrange(0,len(uniattr)):\n",
    "    loc=uniattr[i]\n",
    "    if os.path.isdir('E:/ProjectTravel/IMG/'+loc):\n",
    "        #print \"yes\"+loc\n",
    "        continue\n",
    "    else:\n",
    "        print (loc)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#改寫連結\n",
    "soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "locImg={}\n",
    "locImgHref=[]\n",
    "for l in soup.select('img.widget-runway-card-background-flicker-hack'):\n",
    "    if \"proxy\" in l[\"src\"]:\n",
    "        locImgHref.append(\"https:\" + l[\"src\"].split(\"=w\")[0] + \"=w5000\") \n",
    "        print locImgHref\n",
    "    elif \"/w\" in l[\"src\"]:\n",
    "        locImgHref.append(\"https:\" + l[\"src\"].split(\"/w\")[0] + \"/w5000/photo\") #/w:可能環景圖\n",
    "        print l[\"src\"]\n",
    "    elif \"ggpht.com\" in l[\"src\"]:\n",
    "        continue\n",
    "    else:\n",
    "        locImgHref.append(\"https:\" + l[\"src\"].split(\"/s\")[0] + \"/s5000/photo\")\n",
    "        print l[\"src\"]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#動態建立資料夾\n",
    "import os\n",
    "dir = u'東京鐵塔'\n",
    "os.mkdir('E:\\ProjectTravel\\ '+dir) #(\"\\ \":建在下一層)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#寫出到.json\n",
    "with open('E:\\ProjectTravel\\IMG\\TokyoTower\\hrefs.json' , 'w') as f:\n",
    "    json.dump(locImgHref, f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#匯入.json\n",
    "import json\n",
    "with open('E:\\ProjectTravel\\IMG\\TokyoTower\\hrefs00.json' , 'r') as f:\n",
    "    fhrefs = json.load(f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#檢視.json\n",
    "print json.dumps(fhrefs, encoding='UTF-8', ensure_ascii=False, sort_keys=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#下載\n",
    "import requests\n",
    "import shutil \n",
    "for i in xrange(0,len(fhrefs)):\n",
    "    url = fhrefs[i]\n",
    "    res = requests.get(url, stream=True)\n",
    "    fname = 'TokyoTower'+'{:0>4}'.format(i+1)+'.jpg'\n",
    "    with open('E:/ProjectTravel/IMG/TokyoTower/'+fname, 'wb') as f:\n",
    "        shutil.copyfileobj(res.raw, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### GoogleMap w/ 原圖(多點)\n",
    "- 進入照片特輯, 分析html, 找出特定字串\n",
    "- 取得原始照片連結.json, 整理下載\n",
    "- Element is not clickable:https://www.seleniumeasy.com/selenium-tutorials/element-is-not-clickable-at-point-selenium-webdriver-exception"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import codecs\n",
    "with codecs.open('C:/Users/BIG DATA/Downloads/jptour.txt', 'r', encoding='utf-8') as file:\n",
    "    attr = file.readlines()\n",
    "uniattr=[]\n",
    "for i in xrange(0,len(attr)):\n",
    "    uattr = attr[i].strip()\n",
    "    uniattr.append(uattr)\n",
    "print repr(uniattr[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#自動載圖(被擋驗證不過)\n",
    "\n",
    "import codecs\n",
    "with codecs.open('C:/Users/BIG DATA/Downloads/jptour.txt', 'r', encoding='utf-8') as file:\n",
    "    attr = file.readlines()\n",
    "uniattr=[]\n",
    "for i in xrange(0,len(attr)):\n",
    "    uattr = attr[i].strip()\n",
    "    uniattr.append(uattr)\n",
    "\n",
    "for i in xrange(0,len(uniattr)):\n",
    "    from selenium import webdriver\n",
    "    from selenium.webdriver.common.by import By\n",
    "    from selenium.webdriver.common.keys import Keys\n",
    "    from selenium.webdriver.support.ui import Select\n",
    "    from selenium.webdriver.support.ui import WebDriverWait\n",
    "    from selenium.webdriver.support import expected_conditions as EC\n",
    "    from selenium.common.exceptions import NoSuchElementException\n",
    "    from selenium.common.exceptions import NoAlertPresentException\n",
    "    from selenium.webdriver.common.action_chains import ActionChains\n",
    "    import unittest, time, re\n",
    "    from bs4 import BeautifulSoup \n",
    "    import json,io,re,os\n",
    "    import requests\n",
    "    import shutil\n",
    "\n",
    "    driver = webdriver.Firefox()\n",
    "    #放到最大避免找不到element\n",
    "    driver.set_window_size(1024, 600)\n",
    "    driver.maximize_window()\n",
    "    driver.implicitly_wait(30) #最多等30s\n",
    "    driver.get(\"https://www.google.com.tw/maps\")\n",
    "    loc = uniattr[i]\n",
    "    #wait直到JS生成搜尋鈕:\n",
    "    wait = WebDriverWait(driver,20).until(EC.visibility_of_element_located((By.CSS_SELECTOR, 'div.scene-footer-container.noprint')))\n",
    "    driver.find_element_by_id(\"searchboxinput\").send_keys(loc)\n",
    "    #移動到搜尋鈕並按下\n",
    "    search = driver.find_element_by_css_selector(\"button.searchbox-searchbutton\") \n",
    "    ActionChains(driver).move_to_element(search).click(on_element=None).perform()\n",
    "    \n",
    "    #照片\n",
    "    waitpic = WebDriverWait(driver,30).until(EC.visibility_of_element_located((By.CSS_SELECTOR, 'button.widget-pane-section-image-pack-button')))\n",
    "    searchpic = driver.find_elements_by_css_selector(\"button.widget-pane-section-image-pack-button\")[0]\n",
    "    ActionChains(driver).move_to_element(searchpic).click(on_element=None).perform()\n",
    "    searchpic.click();\n",
    "    WebDriverWait(driver, 30).until(lambda driver: driver.find_element_by_css_selector('.widget-pane-term-link'))\n",
    "    WebDriverWait(driver, 30).until(lambda driver: driver.find_element_by_css_selector('a.fineprint-item.fineprint-padded.noprint'))\n",
    "    time.sleep(30)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(str(html.encode('utf-8')),'html.parser')\n",
    "    engloc = soup.select(\"div.widget-pane-section-header-title h1\")[0].text #存英文景點名\n",
    "    driver.quit()\n",
    "    \n",
    "    t1 = soup.select('a.gb_Me.gb_Ha.gb_rb')[0]['href']\n",
    "    t1_match =  re.search('0x(.{37})%',t1).group(0)\n",
    "    text1 = re.sub(\":\",\"%3A\",t1_match)\n",
    "    text2 = soup.select('.widget-pane-section-image-pack-button')[0]['jstrack']\n",
    "    request_url = \"https://www.google.com.tw/maps/preview/photo?authuser=0&hl=zh-TW&pb=!1e2!3m2!1s%s!9e0!5m42!2m2!1i203!2i100!3m1!2i100!7m35!1m3!1e1!2b0!3e3!1m3!1e2!2b1!3e2!1m3!1e2!2b0!3e3!1m3!1e3!2b0!3e3!1m3!1e4!2b0!3e3!1m3!1e8!2b0!3e3!1m3!1e3!2b1!3e2!1m4!1e5!2b0!3e1!4e2!2b1!4b1!9b0!6m3!1s%s!7e81!15i16698\"%(text1,text2)\n",
    "    #print text1,text2\n",
    "    #print request_url\n",
    "    headers = {\n",
    "    'user-agent':'Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:46.0) Gecko/20100101 Firefox/46.0',\n",
    "    'Cookie':\"NID=79=CPQLMgjGLkAavsAHRIAgZEuYDTfOo0fkHu_Oni9keVFAOoTbh0khCBg43390Rx-Qd8Vhakd11F0gCfKVJQC-v7ffiKjxGdXjf90px2Ly60ox-3Jfi-1Uaj1kYt6xZNDL7vvTZ7vl5Iy3dbw; GOOGLE_ABUSE_EXEMPTION=ID=b1c5d767ddcc97bd:TM=1466858065:C=c:IP=191.101.12.120-:S=APGng0uD_da7U7FrqGA5gRlIi0JVbB7wBQ; OGPC=5061821-1:; DV=svtzA9IFA1EVLEWZLaMIXfSZLBwPqwI\"}\n",
    "    res = requests.get(request_url,headers=headers)\n",
    "    print res.text\n",
    "    \n",
    "    #文字轉.json\n",
    "    imgjson = res.text.split(')]}\\'')[1]\n",
    "    with io.open('E:/ProjectTravel/IMG/temp.json', 'w', encoding='utf-8') as file:\n",
    "        file.write(imgjson)    \n",
    "    #.json讀入\n",
    "    with open('E:/ProjectTravel/IMG/temp.json', 'r') as f:\n",
    "        hrefs = json.load(f)\n",
    "    #改寫連結\n",
    "    imghrefs=[]\n",
    "    for i in xrange(0,len(hrefs[0])):\n",
    "        if re.search('^(\\d)+$',hrefs[0][i][0]):\n",
    "            imghrefs.append(\"https://static.panoramio.com.storage.googleapis.com/photos/1920x1280/\"+hrefs[0][i][0]+\".jpg\") \n",
    "            #print imghrefs[-1]\n",
    "        elif re.search('^-(.{23,})',hrefs[0][i][0]):\n",
    "            imghrefs.append(\"https://lh3.ggpht.com/\" + hrefs[0][i][0] + \"/s2000/photo\") \n",
    "            #print imghrefs[-1]\n",
    "        elif re.search('^http',hrefs[0][i][0]):\n",
    "            imghrefs.append(hrefs[0][i][0])\n",
    "            #print imghrefs[-1]\n",
    "        else:\n",
    "            print hrefs[0][i][0]\n",
    "\n",
    "    #連結寫出保存 \n",
    "    img_ReqUrl={}\n",
    "    img_ReqUrl[loc]=[engloc,imghrefs]\n",
    "    with open('E:/ProjectTravel/IMG/img_ReqUrl.json' , 'a') as f:\n",
    "        json.dump(img_ReqUrl, f)          \n",
    "    #動態建立資料夾\n",
    "    import os\n",
    "    os.mkdir('E:/ProjectTravel/IMG/'+loc)\n",
    "    #下載\n",
    "    import requests\n",
    "    import shutil \n",
    "    for i in xrange(0,len(imghrefs)):\n",
    "        url = imghrefs[i]\n",
    "        res = requests.get(url, stream=True)\n",
    "        fname = loc+'{:0>4}'.format(i+1)+'.jpg'\n",
    "        with open('E:/ProjectTravel/IMG/'+loc+'/'+fname, 'wb') as f:\n",
    "            shutil.copyfileobj(res.raw, f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#挖空取代\n",
    "from bs4 import BeautifulSoup\n",
    "#print type(html)\n",
    "t1 = soup.select('a.gb_Me.gb_Ha.gb_rb')[0]['href']\n",
    "t1_match =  re.search('0x(.{37})%',t1).group(0)\n",
    "text2 = soup.select('.widget-pane-section-image-pack-button')[0]['jstrack']\n",
    "print t1_match,text2\n",
    "request_url = \"https://www.google.com.tw/maps/preview/photo?authuser=0&hl=zh-TW&pb=!1e2!3m2!1s%s!9e0!5m42!2m2!1i203!2i100!3m1!2i100!7m35!1m3!1e1!2b0!3e3!1m3!1e2!2b1!3e2!1m3!1e2!2b0!3e3!1m3!1e3!2b0!3e3!1m3!1e4!2b0!3e3!1m3!1e8!2b0!3e3!1m3!1e3!2b1!3e2!1m4!1e5!2b0!3e1!4e2!2b1!4b1!9b0!6m3!1s%s!7e81!15i16698\"%(text1,text2)\n",
    "print request_url"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "#迭代取字典值:http://www.php101.cn/2015/01/15/Python中的迭代/\n",
    "for value in img_ReqUrl.itervalues():\n",
    "    #print value[0]\n",
    "    #print value[1]\n",
    "    print img_ReqUrl[loc][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xgh8clqZXuV_c6SC10pfrw\n",
      "jzCz5scFfCF2zU6AxSkP3w\n",
      "xxf3buZVrAOICcI-p2P1ew\n",
      "0rY6xrdS4O5M0ZP5YlzBBQ\n",
      "HOrZaZ3NAICLZq1NHknwbg\n",
      "2bQybTl8pHA1WXeD5Ix7yg\n",
      "sHuuHYBkTrQoE89ik0lYwA\n",
      "jIr-33I8m4LvUzrF87QzAQ\n",
      "NNL7RpMRUkmsCQKhYw_4gQ\n",
      "4_F5hIX6IUc9j1DNqvI2qg\n",
      "o2jbfJzQ4Q7oavMUWuMEBg\n"
     ]
    }
   ],
   "source": [
    "#手動原圖(載XML)\n",
    "\n",
    "import json,io,re,os\n",
    "loc = u\"仁和寺\"\n",
    "engloc = \"Ninna-ji\"\n",
    "#.txt轉json\n",
    "with io.open('C:/Users/BIG DATA/Downloads/f (31).txt', 'r', encoding='utf-8') as file:\n",
    "    res = file.read()\n",
    "imgjson = res.split(')]}\\'')[1]\n",
    "with io.open('E:/ProjectTravel/IMG/temp.json', 'w', encoding='utf-8') as file:\n",
    "    file.write(imgjson)    \n",
    "#.json讀入\n",
    "with open('E:/ProjectTravel/IMG/temp.json', 'r') as f:\n",
    "    hrefs = json.load(f)\n",
    "#改寫連結\n",
    "imghrefs=[]\n",
    "for i in xrange(0,len(hrefs[0])):\n",
    "    if re.search('^(\\d)+$',hrefs[0][i][0]):\n",
    "        imghrefs.append(\"https://static.panoramio.com.storage.googleapis.com/photos/1920x1280/\"+hrefs[0][i][0]+\".jpg\") \n",
    "        #print imghrefs[-1]\n",
    "    elif re.search('^-(.{23,})',hrefs[0][i][0]):\n",
    "        imghrefs.append(\"https://lh3.ggpht.com/\" + hrefs[0][i][0] + \"/s2000/photo\") \n",
    "        #print imghrefs[-1]\n",
    "    elif re.search('^http',hrefs[0][i][0]):\n",
    "        imghrefs.append(hrefs[0][i][0])\n",
    "        #print imghrefs[-1]\n",
    "    else:\n",
    "        print hrefs[0][i][0]\n",
    "\n",
    "#連結寫出保存 \n",
    "img_ReqUrl={}\n",
    "img_ReqUrl[loc]=[engloc,imghrefs]\n",
    "with open('E:/ProjectTravel/IMG/img_ReqUrl.json' , 'a') as f:\n",
    "    json.dump(img_ReqUrl, f)\n",
    "        \n",
    "#動態建立資料夾\n",
    "import os\n",
    "os.mkdir('E:/ProjectTravel/IMG/'+loc)\n",
    "#下載\n",
    "import grequests\n",
    "import requests\n",
    "import shutil \n",
    "for i in xrange(0,len(imghrefs)):\n",
    "    url = imghrefs[i]\n",
    "    res = requests.get(url, stream=True) #grequest:https://pypi.python.org/pypi/grequests\n",
    "    fname = loc+'{:0>4}'.format(i+1)+'.jpg'\n",
    "    with open('E:/ProjectTravel/IMG/'+loc+'/'+fname, 'wb') as f:\n",
    "        shutil.copyfileobj(res.raw, f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#下載 w/ grequests(失敗)\n",
    "import grequests\n",
    "import requests\n",
    "import shutil \n",
    "for i in xrange(0,len(imghrefs)):\n",
    "    url = imghrefs[i]\n",
    "    res = requests.get(url, stream=True) #grequest:https://pypi.python.org/pypi/grequests\n",
    "    fname = loc+'{:0>4}'.format(i+1)+'.jpg'\n",
    "    with open('E:/ProjectTravel/IMG/'+loc+'/'+fname, 'wb') as f:\n",
    "        shutil.copyfileobj(res.raw, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
